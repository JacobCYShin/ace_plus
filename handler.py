import base64
import os
import uuid
import subprocess
import runpod
from huggingface_hub import snapshot_download

# ğŸ”½ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ëŸ°íƒ€ì„ì— í™˜ê²½ë³€ìˆ˜ í†µí•´ í† í° ì‚¬ìš©)
def download_model():
    hf_token = os.getenv("HF_TOKEN")
    snapshot_download(
        repo_id="black-forest-labs/FLUX.1-Fill-dev",
        local_dir="models/flux-fill",
        local_dir_use_symlinks=False,
        token=hf_token,
        ignore_patterns=["*.safetensors"]
    )

# ğŸ”½ ìš”ì²­ ì²˜ë¦¬ í•¨ìˆ˜
def handler(event):
    instruction = event["input"]["instruction"]
    input_image_path = event["input"]["input_reference_image"]
    output_image_path = f"/tmp/{uuid.uuid4().hex}.jpg"

    command = [
        "python3", "infer_lora.py",
        "--instruction", instruction,
        "--input_reference_image", input_image_path,
        "--task_type", "portrait",
        "--task_model", "models/model_zoo.yaml",
        "--cfg_folder", "config",
        "--save_path", output_image_path,
        "--infer_type", "diffusers"
    ]

    result = subprocess.run(command, capture_output=True, text=True)

    if result.returncode != 0:
        return {
            "error": "Inference failed",
            "stderr": result.stderr,
            "stdout": result.stdout
        }

    with open(output_image_path, "rb") as img_file:
        image_bytes = img_file.read()
        image_base64 = base64.b64encode(image_bytes).decode("utf-8")

    return {
        "output_image": image_base64
    }

download_model()  # ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë‹¤ìš´ë¡œë“œ

# âœ… RunPod ì„œë²„ë¦¬ìŠ¤ ì‹œì‘ ì§€ì 
runpod.serverless.start({"handler": handler})
